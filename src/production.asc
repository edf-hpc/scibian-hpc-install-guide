= Production procedures

In this chapter are listed all the technical procedures to follow for
regular operations occurring during the production phase of the supercomputer.
This notably includes changing any encryption or authentication key,
changing passwords, reinstalling nodes, etc.

== MAC address change

This procedure explains how to modify the Puppet-HPC configuration to change an
hardware Ethernet address after a motherboard replacement, for example.

First, the yaml file in the hieradata repository containing the
`master_network` hash must be edited to replace the old hardware address. A
description of this hash can be found in the Installation section of this guide.

The modified configuration must be pushed to the shared administration
directory with the `hpc-config-push` command:

----
# hpc-config-push
INFO: creating archive /tmp/puppet-config-push/tmp_ndq0ujz/puppet-config-environment.tar.xz
INFO: S3 push: pushing data in bucket s3-system
----

Then apply the configuration on the `service` nodes, who runs the DHCP server:

----
# hpc-config-apply
----

NOTE: It is not possible to run the `hpc-config-apply` command on all the
service nodes at the same time exactly. A short delay must be respected as the
Ceph service can be disturbed by a restart of the network service.

include::prod/keys.asc[]

== Administration node re-installation

This procedure will wipe the first disk of the admin node, if some
customizations are not in the Puppet configuration, this should be handled
separately.

Before, powering off the administration node, check that:

- There is an alternative route to connect to the service node (can be the
  service nodes themselves)
- It is possible to connect to the BMC IPMI, and especially to the Serial Over
  LAN console
- It is possible to connect to the Ethernet administration network switch

The administration node has no critical service in the reference architecture,
so it can simply be powered off:

----
# poweroff
----

NOTE: In some Ethernet bonding setups, the node cannot do a PXE boot with an
active bonding configuration on the Ethernet switch. If this is the case, refer
to the documentation of the network switch to disable the bonding configuration.

To be re-installed, the administration node must perform a network boot. This
can be configured with `ipmitool(1)` installed on a host that has access to the
BMC network interface:

----
# ipmitool -I lanplus -H <bmc host> -U <bmc username> -P chassis bootdev pxe
# ipmitool -I lanplus -H <bmc host> -U <bmc username> -P chassis power on
----

Next steps will happen once the node is installed and has rebooted, the
installation can be followed through serial console:

----
# ipmitool -I lanplus -H <bmc host> -U <bmc username> -P sol activate
----

NOTE: If the Ethernet switch configuration had to be modified to setup PXE boot,
the modification must be reverted to its nominal status.

== Service node re-installation

Before re-installing a Service node, active Virtual Machines on the nodes
should be migrated away from the node. Clara can be used to list the active VMs
and do the live migration.

Listing the VMs:

----
# clara virt list | grep clserviceX
----

Migrate the live VMs with the command:

----
# clara virt migrate <vmname> --dest-host clserviceY
----

These points should be checked before turning off a Service Node:

 * The ceph cluster should be `HEALTH_OK` (`ceph health`), with at least three
   OSD `in`
 * `consult` should return services as passing on at least three nodes
 * On an Intel Omni-Path cluster, the `opafabricinfo` should return at least one
   Master and one Standby node

Once there is no VM remaining on the node, it can be powered off safely, the
other Service node should ensure there is no service outage. The power off can
be done from the node itself:

----
# poweroff
----

NOTE: In some Ethernet bonding setups, the node cannot do a PXE boot with an
active bonding configuration on the Ethernet switch. If this is the case, refer
to the documentation of the network switch to disable the bonding configuration.

To be re-installed, the service node must perform a network boot. This can be
configured with *clara*:

----
# clara ipmi pxe clserviceX
# clara ipmi on clserviceX
----

Next steps will happen once the node is installed and as rebooted, the
installation can be followed through serial console:

----
# clara ipmi connect clserviceX
----

After a Service node re-installation, the ceph services: OSD, MDS and RadosGW
should be reconfigured automatically by the Puppet HPC configuration. The Mon
service (not present on every node), must be boot-strapped again. This procedure
is described with other <<bootstrap-ceph-mon, Ceph bootstrap procedures>>.

In order to validate the generic service node re-installation, there are some
relevant checks to perform.

* High-Speed network manager (Intel Omni-Path):

----
# opafrabricinfo
----

The reinstalled node must appear as a *Master* or *Standby* node.

* Check the ceph cluster is healthy:

----
# ceph status
----

The cluster should be `HEALTH_OK` with all OSDs, Mons and MDSs.

* Consul:

----
# consult
----

All services on all nodes should have the state `passing`.

NOTE: If the Ethernet switch configuration had to be modified to setup PXE boot,
the modification must be reverted to its nominal status.

== Frontend access

[[production-frontend-drain]]
=== Draining

To perform a scheduled reboot of a frontend it is better to avoid new
connection going to the frontend node that will be rebooted. The new
connections are <<arch-adv-frontend-ha, highly available and load balanced>>
with IPVS.

It is possible to remove a frontend from the pool of node accepting new
connections without killing active connections with the `ipvsadm` command by
setting the weight of a node to 0.

To list the current weight, on a frontend:

----
# ipvsadm -ln
IP Virtual Server version 1.2.1 (size=4096)
Prot LocalAddress:Port Scheduler Flags
  -> RemoteAddress:Port           Forward Weight ActiveConn InActConn
TCP  172.16.1.16:22 rr persistent 600
  -> 172.16.1.11:22              Route   1      10         0
  -> 172.16.1.12:22              Route   1      6          0
  -> 172.16.1.13:22              Route   1      1          0
  -> 172.16.1.14:22              Route   1      15         0
  -> 172.16.1.15:22              Route   1      1          0
----

To avoid a frontend node being attributed to new sessions, the weight of the
node can be manually set to 0. This setting does not completely forbid new
connection to go to the node, if a user already has a session, new session will
go to the same node regardless of the weight. This setting also does not block
connections made directly to the node and not the virtual IP address.

----
# ipvsadm -e -t 172.16.1.16:22 -r 172.16.1.11:22 -w 0
# ipvsadm -ln
IP Virtual Server version 1.2.1 (size=4096)
Prot LocalAddress:Port Scheduler Flags
  -> RemoteAddress:Port           Forward Weight ActiveConn InActConn
TCP  172.16.1.16:22 rr persistent 600
  -> 172.16.1.11:22              Route   0      10         0
  -> 172.16.1.12:22              Route   1      6          0
  -> 172.16.1.13:22              Route   1      1          0
  -> 172.16.1.14:22              Route   1      15         0
  -> 172.16.1.15:22              Route   1      1          0
----

The modification can be reversed by setting the weight back to 1 manually.

----
# ipvsadm -e -t 172.16.1.16:22 -r 172.16.1.12:22 -w 1
----
