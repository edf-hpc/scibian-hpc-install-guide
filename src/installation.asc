= Installation procedures

////
TODO: fill this chapter to document all the steps to follow in order to install
a Scibian HPC cluster.
////

== Internal repository

////
TODO: document the steps to initialize the internal hieradata repository
////

== Cluster definition

////
TODO: document how-to write cluster definition in hiera, with reference to
[Puppet-HPC reference documentation]
////

== Generate keys

////
TODO: document the steps to generate the keys, certificates, and so on.
////
 
== Install admin node

////
TODO: document the steps to boot the admin node with rikenter and
install/configure minimal installation system in live.
////

== Install generic servers

////
TODO: document how-to install and configure generic service nodes.
////

== Configure Ceph

////
TODO: document how-to deploy and configure Ceph cluster.
////

=== Service initialization

==== mon init 

This procedure only works on a running cluster, the initial mon creation
uses another command.

From an *admin* node:

--------
# cd <ceph deploy directory>
# ceph-deploy --overwrite-conf mon create <mon hostname>
--------

==== osd

==== mds

MDS has no state on the node, the configuration in puppet is sufficient
to initialize the service.

==== radosgw

RadosGW has no state on the node, the configuration in puppet is sufficient
to initialize the service.

== Re-install admin node

////
TODO: document how-to install admin node with generic service nodes.
////

== Install virtual machines

////
TODO: document how-to install and configure virtual machines with references to
[bootstraping guides] for service.
////

== Build diskless image

Diskless nodes use squashfs images downloaded at boot. A simple way to
generate these images is to use https://github.com/edf-hpc/clara[`clara`].
Once configured, `clara image create` can be used to build Debian image(s).

Clara can install a selected list of packages into the image, manage
the repositories used and add specific files and directories.

Example:
-------------------------------------------------------------------------------
# clara image create scibian8
-------------------------------------------------------------------------------

Clara can also generate an `initrd` (initial ramdisk) to use with the image.
It can download the image either by http or bitorrent protocol.

Example:
-------------------------------------------------------------------------------
# clara image initrd scibian8
-------------------------------------------------------------------------------

Initrd must be regenerated each time the kernel image is modified.

See the http://edf-hpc.github.io/clara/[clara documentation]  for a full
list of options and possibilities.

Every time the image and the initrd are regenerated, they must be made
available to the deployment system.

== Boot nodes

To remotely start the nodes, you can use https://github.com/edf-hpc/clara[`clara`].
The ipmi plugin from clara is used for powering on/off selected nodes,
managing the boot node mode (if you want to install OS on disk or load it in RAM)
and accessing to the remote console.

See the http://edf-hpc.github.io/clara/[clara documentation] for a full
list of options and possibilities.

The commands from the following example, show how to reboot a node with
the boot menu, choose the operating system and boot mode between "diskless"
or "on disk".

Example:
-------------------------------------------------------------------------------
# clara ipmi pxe <node>
# clara ipmi reboot <node>
# clara ipmi connect <node>
-------------------------------------------------------------------------------

After the last command, when the login prompt is shown, you can connect on node
as root and monitor the progress of the puppet configuration by running
the following command:

-------------------------------------------------------------------------------
# journalctl -f -u hpc-config-apply
-------------------------------------------------------------------------------

When the network is up in the node you can also disconnect from the console
(press on "!" and "." keys as explained on the clara documentation) and
connect to the node via ssh.
