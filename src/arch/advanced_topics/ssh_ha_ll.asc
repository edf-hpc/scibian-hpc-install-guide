[[arch-adv-frontend-ha]]
=== Frontend nodes: SSH load-balancing and high-availability

The frontend nodes offer a virtual IP address on the WAN network that features
both an highly-available and load-balanced SSH service for users to access the
HPC cluster. The load-balancing feature automatically distributes users on all
available frontend nodes. This load-balancing is operated with persistence so
that users (based on their source IP address) are always redirected to the same
frontend node in a time frame. Behind the virtual IP address, the
high-availability of the SSH service is also ensured in case of outage on a
frontend node. These load-balancing and high-availability features are ensured
by the Keepalived software.

For security reasons, a firewall is also set up on the frontend nodes to control
outgoing network traffic. This firewall service is managed by Shorewall, a
high-level configuration tool for Linux netfilter. Because of all the various
network flows involved in Keepalived, it must be tightly integrated with the
firewall rules. The following diagram illustrates both the network principles
behind the high-availability/load-balancing mechanisms and the integration with
the software components of the firewall:

[[img-ssh_ll_ha]]
.sshd load-balancing HA mechanism with firewall integration
image::src/img/sshd_frontend_ha_ll.svg[width=650]

The Keepalived sofware checks all the frontend nodes using the
VRRPfootnote:[Virtual Router Redundancy Protocol] protocol on the WAN network interfaces (purple arrow in the diagram). This protocol must be allowed in the
OUTPUT chain of the firewall so that Keepalived can work properly.

On the master frontend node, the HA virtual IP address is set on the network
interface attached to the WAN network. The Keepalived software configures the
IPVSfootnote:[IP Virtual Server] Linux kernel load-balancer to redirect new TCP
connections with a Round-Robin algorithm. Therefore, a part of the TCP connections is redirected to the `sshd` daemon of other frontend nodes (orange arrow in
the diagram). An exception must be specified in the OUTPUT chain of the
firewall to allow these redirected connections.

To perform such redirections, IPVS simply changes the destination MAC address,
to set the address of the real destination frontend, in the Ethernet layer of
the first packet of the TCP connection. However, the destination IP address does
not change: it is still the virtual IP address.

On the slave frontend nodes, the HA virtual IP address is set on the loopback
interface. This is required to make the kernel accept the redirected packets
from the master frontend node addressed to the virtual IP address. In order to
avoid endless loops, the IPVS redirection rules are disabled on slave frontend
nodes or else, packets would be redirected endlessly.

By default, the Linux kernel answers the ARP requests coming from any network
device for any IP address attached to any network device. For example, on a
system with two network devices: `eth0` with `ip0` and `eth1` with `ip1`, if
an ARP request is received for `ip1` on `eth0`, the kernel positively responds
to it, with the MAC address of `eth0`. Though it is convenient in many cases,
this feature is annoying on the frontend nodes, since the virtual IP address is
set on all of them. Consequently all frontend nodes answer the ARP requests
coming from the WAN default gateway. In order to avoid this behaviour, the
`net.ipv4.conf.<netif>.arp_ignore` and `net.ipv4.conf.<netif>.arp_announce`
sysctl Linux kernel parameters, where `<netif>` is the network interface
connected to the WAN network, are respectively set to 1 and 2. Please refer to
the Linux documentation for more details on these parameters and their values:
http://www.kernel.org/doc/Documentation/networking/ip-sysctl.txt

The Keepalived software also checks periodically the health of each frontend 
node with 2 different checks:

 * it tries to perform a TCP connection to the real IP address of each server
on the TCP/22 port (green arrow in the diagram). An exception  must be present 
in the OUPUT chain of the firewall to allow these connections
 * it checks the content of a state file exported by each server via the real
IP address on the 3143 port (yellow arrow in the diagram). An exception 
must be present in the OUPUT and in the INPUT chain as well of the firewall 
to allow these connections.
The state file is written locally by a cron job on each server. We use
the "warewulf_nhc" program, the same used on the compute nodes, to ensure
server health. Basically, the content of the state file is the output of the
"nhc" command. It is empty if the "nhc" program detect no errors and it contains
the list of failed checks if not.

There is an unexplained behaviour in the Linux kernel where the Netfilter
conntrack module considers that new TCP connections redirected by IPVS to the
local `sshd` daemon have an invalid cstate. This point can be verified with well placed iptable rules using the LOG destination. This causes the TCP SYN/ACK
answer from the `sshd` to be blocked by the OUTPUT chain since it considers the
 connection is new and not related to any incoming connections. To workaround
this annoying behaviour, an exception has been added in the OUTPUT chain of the
firewall to accept connections with a source port that is TCP/22 and a source IP address that is the virtual IP address. This is not totally satisfying in
terms of security but there is no known easy or obvious way to exploit this
security exception from a user perspective for other purposes.

If a slave frontend node becomes unavailable, Keepalived detects it either with
VRRP checks, or with TCP checks in case only the `sshd` daemon is crashed. The
IPVS rules are changed dynamically to avoid redirecting new TCP connections to
this failing node.

If the master frontend node becomes unavailable, the Keepalived software selects a new master node within the other frontend nodes. Then, on this new master
node, Keepalived restores the IPVS redirection rules (since they were previously
disabled to avoid loops) and moves the virtual IP address from the loopback
interface to the WAN network interface.

If a frontend node is scheduled to be turned of, it is possible to
<<production-frontend-drain, drain>> it.
