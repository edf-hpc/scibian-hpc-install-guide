[[arch-extsrv]]
== External services

A Scibian HPC cluster is designed to be mainly self contained and to continue
running jobs even if it is cut off from the rest of the organization network.
There is some limits to this though and some external services are needed.
Critical external services are replicated inside the cluster though, to avoid
losing availability of the cluster if the connection to external service is
cut.

=== Base services

==== LDAP

The reference cluster architecture provides a highly available LDAP service,
but it is only meant as a replica of an external LDAP service. The organization
must provide an LDAP service with suitable replica credentials.

Only the LDAP servers (Proxy virtual machines) connect to these servers.

==== NTP

The generic service nodes are providing NTP servers for the whole cluster.
Those servers must be synchronized on an external NTP source. This could be an
organization NTP or a public one (eg. `spool.ntp.org`).

Only the NTP servers (Generic Service nodes) connect to these servers.

==== Package repositories

The normal way for a Scibian HPC Cluster to handle package repositories (APT)
is to provide a proxy cache to organization or public distribution
repositories. Alternatively, it is possible to mirror external repositories on
the cluster (with `clara` and Ceph/S3).

Proxy cache needs less maintenance and is the preferred solution. Local mirrors
can be used when reliable connection to external repositories is unreliable.

Only the Proxy Cache servers (Generic Service nodes) connect to these servers.
In the mirror mode, only the admin node uses them.

==== DNS

External DNS service is not strictly necessary but is hard to not configure if
the cluster must use organization or public services (License servers, NAS...).

The external DNS servers are configured as recursive in the local DNS server
configuration.

Only the DNS servers (Generic Service nodes) connect to these servers.

=== Optional services

==== NAS

It is frequent to mount (at least on the frontend nodes) an external NAS space
to copy data in and out of the cluster.

==== Graphite

In the reference architecture all system metrics collected on the cluster (by
collectd) are pushed to an external graphite server. This is usually relayed
by the proxy virtual machines. 

==== InfluxDB

In the reference architecture all jobs metrics collected on the cluster are
pushed to an external InfluxDB server. This is usually relayed by the proxy
virtual machines.

==== HPCStats

HPCStats is a tool that frequently connects to the frontend as a normal user to
launch job. It also connects to the SlurmDBD database to get batch job
statistics. The database connection needs a special NAT configuration on the
Proxy virtual machines.

==== Slurm-Web Dashboard

The Slurm-Web Dashboard aggregates data coming from multiple clusters in the
same web interface. To get those data, the client connect to an HTTP REST API
that is hosted on the Proxy virtual machines.

