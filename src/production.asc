= Production procedures

== MAC address change

This procedure explains how to modify the Puppet-HPC configuration to change an
hardware ethernet address after a motherboard replacement, for example.

=== Change the network.yaml file

First, the yaml file in the hieradata repository containing the
`master_network` hash must be edited to replace the old hardware address. A
description of this hash can be found in the Installation section of this guide.

=== Push the new configuration and apply it

The modified configuration must be pushed to the shared administration 
directory with the `hpc-config-push` command:

----
# hpc-config-push
INFO: creating archive /tmp/puppet-config-push/tmp_ndq0ujz/puppet-config-environment.tar.xz
INFO: S3 push: pushing data in bucket s3-system
----

Then apply the configuration on the `service` nodes, who runs the dhcp server:

----
# hpc-config-apply
----

NOTE: It is not possible to run the `hpc-config-apply` on all the service nodes
at the same time exactly. A short delay must be respected as the Ceph service
can be disturbed by a restart of the network service.

== Password/keys changes

////
TODO: document how-to change all passwords, keys (including SSH host keys) and certificates.
////

== Service node re-installation

=== VMs migration

Before re-installing a Service node, active Virtual Machines on the nodes
should be migrated away from the node. Clara can be used to list the active VMs
and do the live migration.

Listing the VMs:

----
admin # clara virt list |grep clserviceX
----

Migrate the live VMs with the command:

----
admin # clara virt migrate <vmname> --dest-host clserviceY
----

=== Power off

These points should be checked before turning off a Service Node:

 * The ceph cluster should be `HEALTH_OK` (`ceph health`), with at least three
   OSD `in`
 * `consult` should return services as passing on at least three nodes
 * On an Intel OmniPath cluster, the `opafabricinfo` should return at least one
   Master and one Standby node

Once there is no VM remaining on the node, it can be powered off safely, the
other Service node should ensure there is no service outage.

The power off can be done from the node itself:

----
clserviceX # poweroff
----

=== PXE setup

In some ethernet bonding setups, the node cannot do a PXE boot with an active
bonding configuration on the ethernet switch. If this is the case, refer to the
documentation of the network switch to disable the bonding configuration.

=== Power on

To be re-installed, the service node must perform a network boot. This can be
configured with *clara*:

----
admin # clara ipmi pxe clserviceX
admin # clara ipmi on clserviceX
----

Next steps will happen once the node is installed and as rebooted, the
installation can be followed through serial console:
----
admin # clara ipmi connect clserviceX
----

=== Ceph

After a Service node re-installation, the ceph services: OSD, MDS and RadosGW
should be reconfigured automatically by the Puppet HPC configuration.

The Mon service (not present on every node), must be boot-strapped again. This
procedure is described with other <<bootstrap-ceph-mon, Ceph bootstrap
procedures>>.

=== Post-reboot checks

High-Speed network manager (Intel OmniPath):

----
admin # opafrabricinfo
----

The reinstalled node must appear as a *Master* or *Standby* node.

Check the ceph cluster is healthy:

----
admin # ceph status
----

The cluster should be `HEALTH_OK` with all OSDs, Mons and MDSs.

Consul:

----
admin # consul
----

All services on all nodes should have the state `passing`.

=== Cleaning

If the ethernet switch configuration had to be modified to setup PXE boot, the
modification must be reverted to its nominal status.
