=== Authentication and encryption keys

Cluster configurations comprises many sensitive data such as passwords, private
keys, confidential files, and so on. The Puppet-HPC stack provides an integrated
mechanism for storing these data securily in the internal configuration
repository. This mechanism is fully explained in the _Puppet-HPC Reference
Documentation_ (chapter _Software Architecture_, section _Sensitive Data
Encryption_). Basically, these data are encrypted using two keys:

* asymmetric PKCS7 key pair for encrypting values in Hiera with eyaml,
* symmetric AES key, named as the _cluster password_, for encrypting files.

These keys are also used to decrypt data on nodes of the cluster _main area_.
If the cluster is composed of only one area (ex: _default_), only these two
keys are involved on the cluster. Otherwise, additional and dedicated keys are
used by the other areas to decrypt their sensitive data.

IMPORTANT: In all cases, only *the keys of the main area are used to manipulate
the sensitive data in the internal configuration repository*. The keys of the
optional other areas are used dynamically and transparently by the hpc-config
utilities in the Puppet-HPC stack.

==== Main area keys bootstrap

The PKCS7 eyaml key pair must be created initially. First, create the directory
for these keys:

[source,bash]
----
mkdir -p /etc/puppet/secure/keys
----

Then, setup the eyaml configuration to use this directory:

[source,bash]
----
mkdir -p ~/.eyaml
cat << EOF > ~/.eyaml/config.yaml
---
  pkcs7_private_key: /etc/puppet/secure/keys/private_key.pkcs7.pem
  pkcs7_public_key: /etc/puppet/secure/keys/public_key.pkcs7.pem
EOF
----

And generate the keys with:

[source,bash]
----
eyaml createkeys
----

Restrict modes and ownership properly on files and directories:

[source,bash]
----
chmod 700 /etc/puppet/secure
chown -R puppet:puppet /etc/puppet/secure/keys
chmod -R 0500 /etc/puppet/secure/keys
chmod 0400 /etc/puppet/secure/keys/*.pem
----

Then, generate the _cluster password_:

[source,bash]
----
openssl rand -base64 32
----

The output of this command must be saved encrypted with eyaml keys in the area
layer of the internal Hiera repository. Create the directory of this layer and
edit the area YAML file with `eyaml`:

[source,bash]
----
mkdir $ADMIN/hpc-privatedata/hieradata/$CLUSTER/areas
eyaml edit $ADMIN/hpc-privatedata/hieradata/$CLUSTER/areas/$MAIN.yaml
----

Where `$MAIN` is the name of the main area (ex: `default` or `infra`).

In the editor, add a line like this, and save:

[source,yaml]
----
cluster_decrypt_password: DEC::PKCS7[<the password given by the openssl command>]!
----

Finally, store an encrypted archive of the eyaml keys in the internal
configuration repository:

[source,bash]
----
# create main area eyaml directory
mkdir -p $ADMIN/hpc-privatedata/files/$CLUSTER/$MAIN/eyaml/$MAIN

# build archive
tar cJf $ADMIN/hpc-privatedata/files/$CLUSTER/$MAIN/eyaml/$MAIN/keys.tar.xz \
    -C /etc/puppet/secure keys

# encrypt archive
$ADMIN/puppet-hpc/scripts/encode-file.sh \
    $ADMIN/hpc-privatedata $CLUSTER \
    $ADMIN/hpc-privatedata/files/$CLUSTER/$MAIN/eyaml/$MAIN/keys.tar.xz

# delete temporary unencrypted archive
rm $ADMIN/hpc-privatedata/files/$CLUSTER/$MAIN/eyaml/$MAIN/keys.tar.xz
----

==== Other areas encryption keys

This step can be skipped if the cluster is composed of only one area.
Otherwise, this step *must be repeated* for all areas except the main one.

First, generate the _cluster password_ of the area:

[source,bash]
----
openssl rand -base64 32
----

Save the output into the area YAML file with `eyaml`:

[source,bash]
----
eyaml edit $ADMIN/hpc-privatedata/hieradata/$CLUSTER/areas/$OTHER.yaml
----

Where `$OTHER` is the name of the other area (ex: `user`).

In the editor, add a line like this, and save:

[source,yaml]
----
cluster_decrypt_password: DEC::PKCS7[<the password given by the openssl command>]!
----

Set a shell variable `KEYS_DIR`, with the path of the other area keys
directory, in order to simplify following commands:

[source,bash]
----
export KEYS_DIR=$ADMIN/hpc-privatedata/files/$CLUSTER/$MAIN/eyaml/$OTHER
----

Create the directories for storing the area eyaml keys, including a `keys`
temporary subdirectory:

[source,bash]
----
mkdir -p $KEYS_DIR/keys
----

Generate the area eyaml keys:

[source,bash]
----
eyaml createkeys \
  --pkcs7-private-key $KEYS_DIR/keys/private_key.pkcs7.pem \
  --pkcs7-public-key $KEYS_DIR/keys/public_key.pkcs7.pem
----

Build the archive and clean temporary files:

[source,bash]
----
# build archive
tar cJf $KEYS_DIR/keys.tar.xz \
    -C $KEYS_DIR keys

# delete temporary keys subdirectory
rm -rf $KEYS_DIR/keys
----

Finally, encrypt the archive and remove the unencrypted version:

[source,bash]
----
# encrypt archive
$ADMIN/puppet-hpc/scripts/encode-file.sh \
    $ADMIN/hpc-privatedata $CLUSTER \
    $KEYS_DIR/keys.tar.xz

# delete temporary unencrypted archive
rm $KEYS_DIR/keys.tar.xz
----

==== SSH host keys

The SSH host keys must stay consistent between node re-installations and/or
diskless reboots. To ensure this, the SSH host keys are generated in the
cluster's files directory of the internal configuration repository before their
first installation and/or diskless boot.

This cluster nodes classifier utility is run by the SSH hostkeys generation
script to get the area of the nodes. Initially, copy the configuration file of
this utility to its target path:

[source,bash]
----
cp $ADMIN/hpc-privatedata/puppet-config/$CLUSTER/cluster-nodes.yaml \
  /etc/hpc-config/cluster-nodes.yaml
----

To generate the hostkeys, the script needs to know the local domain name of the
cluster. By default, the script will use the local domain of the machine where
it runs by default. If this is not correct you must provide the domain in
argument. Run the script with the following command:

[source,bash]
----
puppet-hpc/scripts/sync-ssh-hostkeys.sh \
  hpc-privatedata $CLUSTER [$CLUSTER.$NETDOMAIN]
----

This script ensures that all nodes present in the `master_network` hash have
valid SSH host keys. During this step, the `known_hosts` file will also be
synchronized with the generated keys. This file will be stored in
`hpc-privatedata/files/$CLUSTER/cluster/ssh/known_hosts`.

==== SSH root key

For password-less SSH authentication from the admin and generic service nodes to
all the other nodes of the cluster, SSH authentication keys pair are deployed
for root on the nodes.

First, create the `rootkeys` sub-directory in the cluster's files directory of
the internal configuration repository:

[source,bash]
----
cd $ADMIN && mkdir -p hpc-privatedata/files/$CLUSTER/$MAIN/rootkeys
----

Then, generate the key pair:

[source,bash]
----
ssh-keygen -t rsa -b 2048 -N '' -C root@$CLUSTER \
  -f hpc-privatedata/files/$CLUSTER/$MAIN/rootkeys/id_rsa_root
----

Key type and size can be adjusted. Encode the private key with the
following helper script provided by Puppet-HPC:

[source,bash]
----
puppet-hpc/scripts/encode-file.sh hpc-privatedata $CLUSTER \
  hpc-privatedata/files/$CLUSTER/$MAIN/rootkeys/id_rsa_root
----

Do not forget to remove the generated unencrypted private key:

[source,bash]
----
rm hpc-privatedata/files/$CLUSTER/$MAIN/rootkeys/id_rsa_root
----

Finally, publish the public key with the following parameter in the cluster
specific layer of the hiera repository
`$ADMIN/hpc-privatedata/hieradata/$CLUSTER/cluster.yaml`:

----
openssh::server::root_public_key: <pubkey>
----

==== Root password

The root password is stored hashed in Hiera repository and encrypted with eyaml
keys. Set the root password on the temporary installation node (using `passwd`
command) then extract the resulting hash from `/etc/shadow` file. Get the whole
second field:

----
root:<long password hash>:17763:0:99999:7:::
----

Then paste the hash into the main area Hiera layer using `eyaml` command:

[source,bash]
----
eyaml edit $ADMIN/hpc-privatedata/hieradata/$CLUSTER/areas/$MAIN.yaml
----

Then add this line in the editor:

[source,yaml]
----
profiles::cluster::root_password_hash: DEC::PKCS7[<long password hash>]!
----

The `profiles::cluster::root_password_hash` must be defined in all areas of the
cluster. If the cluster is composed of multiple areas, you must repeat the
steps for all other areas. It is obviously more secure if the password is
different in each area, since an area will not be able to access the hash of
the root password of the nodes in other areas.

[[inst-internalrepo-keys-vip]]
==== VIP encryption keys

The `keepalived` service relies on a shared key to authenticate the nodes
sharing a VRRP instance to manage a virtual IP address (VIP).

With Puppet-HPC, this key is common to all VIP instances of an area. Sensitive
data being local to an area, keys must be generated for each area that includes
nodes sharing a VIP.

Generate a random password with the following command:

[source,bash]
----
makepasswd --minchars=16 --maxchars=16
----

Edit the area YAML file with `eyaml`:

[source,bash]
----
eyaml edit $ADMIN/hpc-privatedata/hieradata/$CLUSTER/areas/$AREA.yaml
----

And save the output of the `makepasswd` command with the following parameter:

[source,yaml]
----
vips_secret: DEC::PKCS7[<password>]!
----

This procedure must be repeated for all areas that include nodes sharing a VIP.
