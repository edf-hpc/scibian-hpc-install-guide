[[inst-nodes]]
== Frontend and compute nodes

On Scibian HPC clusters, the frontend and compute nodes download at boot time a
system image in deployed in RAM which notably gives possibility to have
diskless nodes. For more details about this technique, please refer to the
<<arch-advtpc-boot-diskless,Diskless boot sub-section>> in the _Advanced Topics_
section of the Architecture chapter of this document. The diskless image must be
generated with Clara _images_ plugin on the _admin_ node before booting the
frontend and the compute nodes. These steps are explained in the following
sub-sections.

[[inst-nodes-diskless]]
=== Diskless image generation

The diskless image is generated by the Clara _images_ plugin. This plugin need
some configuration in the cluster specific layer of the Hiera repository. Here
is an example of such configuration:

----
clara_images_target_dir: "%{hiera('admin_dir')}/scibian8"

clara::common_options:
  allowed_distributions:
    value: 'scibian8'

clara::images_options:
  extra_packages_image: "scibian-archive-keyring,hpc-config-apply,scibian-hpc-commons"
  packages_initrd:      "scibian-diskless-initramfs-config"
  etc_hosts:            "10.1.0.101:vipfbservice1,10.1.0.101:apt.service.virtual,10.1.0.10:fbadmin1"

clara::config_options:
  images-scibian8:
    debiandist:                 'jessie'
    debmirror:                  "http://%{hiera('debian_mirror_server')}/%{hiera('debian_mirror_dir')}"
    kver:                       "3.16.0-4-amd64"
    list_repos:                 "deb [arch=amd64,i386] http://%{hiera('debian_mirror_server')}/"
    trg_dir:                    "%{hiera('clara_images_target_dir')}"
    trg_img:                    "%{hiera('clara_images_target_dir')}/scibian8.squashfs"
    preseed_file:               "%{hiera('clara_images_config_dir')}/scibian8/preseed"
    package_file:               "%{hiera('clara_images_config_dir')}/scibian8/packages"
    script_post_image_creation: "%{hiera('clara_images_config_dir')}/scibian8/post.sh"
    list_files_to_install:      "%{hiera('clara_images_config_dir')}/scibian8/filelist"
    dir_files_to_install:       "%{hiera('clara_images_config_dir')}/scibian8/files_dir"
    foreign_archs:              'i386'

clara::live_dirs:
  "%{hiera('clara_images_config_dir')}":
    ensure: directory
  "%{hiera('clara_images_config_dir')}/scibian8":
    ensure: directory
  "%{hiera('clara_images_config_dir')}/scibian8/files_dir":
    ensure: directory

clara::live_files:
  "%{hiera('clara_images_config_dir')}/scibian8/post.sh":
    source: "%{hiera('private_files_dir')}/boot/live/scibian8/post.sh"
    mode: '755'
  "%{hiera('clara_images_config_dir')}/scibian8/preseed":
    source: "%{hiera('private_files_dir')}/boot/live/scibian8/preseed"
  "%{hiera('clara_images_config_dir')}/scibian8/filelist":
    source: "%{hiera('private_files_dir')}/boot/live/scibian8/filelist"
  "%{hiera('clara_images_config_dir')}/scibian8/files_dir/resolv.conf":
    source: "%{hiera('private_files_dir')}/boot/live/scibian8/files_dir/resolv.conf"
  "%{hiera('clara_images_config_dir')}/scibian8/files_dir/no-cache":
    source: "%{hiera('private_files_dir')}/boot/live/scibian8/files_dir/no-cache"
  "%{hiera('clara_images_config_dir')}/scibian8/files_dir/no-recommends":
    source: "%{hiera('private_files_dir')}/boot/live/scibian8/files_dir/no-recommends"
  "%{hiera('clara_images_config_dir')}/scibian8/files_dir/interfaces":
    source: "%{hiera('private_files_dir')}/boot/live/scibian8/files_dir/interfaces"
  "%{hiera('clara_images_config_dir')}/scibian8/files_dir/proxy":
    source: "%{hiera('private_files_dir')}/boot/live/scibian8/files_dir/proxy"
  "%{hiera('clara_images_config_dir')}/scibian8/files_dir/mk_ipmi_dev.sh":
    source: "%{hiera('private_files_dir')}/boot/live/scibian8/files_dir/mk_ipmi_dev.sh"
  "%{hiera('clara_images_config_dir')}/scibian8/files_dir/hpc-config.conf":
    source: "%{hiera('private_files_dir')}/boot/live/scibian8/files_dir/hpc-config.conf"
----

////
NOTE: most of this config can be removed when this bug is fixed:
  https://github.com/edf-hpc/puppet-hpc/issues/113
////

The `clara::live_files` parameter contains a list of files deployed under the
configuration directory of Clara. Their files are:

* `$ADMIN/hpc-privatedata/files/$CLUSTER/boot/live/scibian8/post.sh` is a
  post-generation script run by Clara inside the image environment:

[source,bash]
----
include::../examples/live/post.sh[]
----

This script can notably be used to customize the image or set files and
directories that are required very early in the live boot process before Puppet
run.

* `$ADMIN/hpc-privatedata/files/$CLUSTER/boot/live/scibian8/preseed` contains
  the answers to the Debconf packages configuration questions:

[source]
----
include::../examples/live/preseed[]
----

* `$ADMIN/hpc-privatedata/files/$CLUSTER/boot/live/scibian8/filelist` specifies
  the list of files to copy inside the generated image:

[source]
----
include::../examples/live/filelist[]
----

All the files under the `files_dir` directory are copied without modification
into the image. The required files are:

* `$ADMIN/hpc-privatedata/files/$CLUSTER/boot/live/scibian8/files_dir/resolv.conf`
  is the configuration file for DNS solvers with the virtual IP addresses of the
  cluster's internal DNS servers:

[source]
----
include::../examples/live/resolv.conf[]
----

* `$ADMIN/hpc-privatedata/files/$CLUSTER/boot/live/scibian8/files_dir/no-cache`
  disables packages local caching in APT package manager:

[source]
----
include::../examples/live/no-cache[]
----

* `$ADMIN/hpc-privatedata/files/$CLUSTER/boot/live/scibian8/files_dir/no-recommends`
  disables _recommends_ soft-dependencies installation in APT package manager:

[source]
----
include::../examples/live/no-recommends[]
----

* `$ADMIN/hpc-privatedata/files/$CLUSTER/boot/live/scibian8/files_dir/interfaces`
  is a default network interfaces configuration file to enable DHCP on `eth0`
  interface:

[source]
----
include::../examples/live/interfaces[]
----

* `$ADMIN/hpc-privatedata/files/$CLUSTER/boot/live/scibian8/files_dir/proxy`
  setup cluster's internal packages proxy in APT configuration:

[source]
----
include::../examples/live/proxy[]
----

* `$ADMIN/hpc-privatedata/files/$CLUSTER/boot/live/scibian8/files_dir/mk_ipmi_dev.sh`
  is a workaround script to create the BMC devices inodes the `/dev` virtual
  filesystem very early in the diskless nodes boot process:

[source,sh]
----
include::../examples/live/mk_ipmi_dev.sh[]
----

////
NOTE: this file can probably be removed now that secret is retrieved by HTTP. It
was required when Puppet run inside the initrd environment and the key was
stored inside he motherboard UEFI.
////

* `$ADMIN/hpc-privatedata/files/$CLUSTER/boot/live/scibian8/files_dir/hpc-config.conf`
  is a configuration file for Puppet-HPC `hpc-config-apply` utility:

[source]
----
include::../examples/live/hpc-config.conf[]
----

////
NOTE: this file can be removed when this bug is fixed:
  https://github.com/edf-hpc/puppet-hpc/issues/114
////

Once all these files have been added to the cluster specific files directory,
the Clara _p2p_ plugin must be configured in the cluster specific layer of the
Hiera repository with the following parameter:

----
clara::p2p_options:
  seeders:         "%{hiera('cluster_prefix')}%{my_p2p_tracker}1,%{hiera('cluster_prefix')}%{my_p2p_tracker}2:%{hiera('clara_images_target_dir')}/scibian8.squashfs.torrent"
  trackers:        "10.1.0.51,10.1.0.52:%{hiera('clara_images_target_dir')}/scibian8.squashfs.torrent"
  trackers_port:   '6881'
  trackers_schema: 'http'
----

Push and apply the configuration on the admin node:

----
# hpc-config-push && hpc-config-apply
----

Now that Clara is setup, the image can be created with the following command:

----
# clara images create scibian8
----

Also create the associated initrd environment:

----
# clara images initrd scibian8
----

Deploy the generate image and initrd to the _p2p nodes with!

----
# clush -g p2p mkdir -p /var/www/diskless/scibian8
# clush -g p2p \
  --copy /var/cache/admin/scibian8/{initrd-3.16.0-4-amd64,vmlinuz-3.16.0-4-amd64} \
  --dest /var/www/diskless/scibian8
# clush -g p2p \
  --copy /var/cache/admin/scibian8/{scibian8.squashfs.torrent,scibian8.squashfs} \
  --dest /var/www/diskless/scibian8
----

Restart peer-to-peer services to load new files:

----
# clara p2p restart
----

The diskless environment is finally ready and available to frontend and compute
nodes.

=== Boot nodes

Before booting the frontend and compute nodes, they must be declared in the
internal configuration repository in the first place. Append the nodes to the
`boot_params` hash in `$ADMIN/hpc-privatedata/hieradata/$CLUSTER/cluster.yaml`:

[source,yaml]
----
boot_params:
  [...]
  fbfront[1-2]:
    cowsize:            '8G'
    boot_os:            'scibian8_ram'
    ipxebin:            'ipxe_noserial.bin'
  fbcn[01-04]:
    boot_os:            'scibian8_ram'
    ipxebin:            'ipxe_noserial.bin'
  fbgn01:
    cowsize:            '8G'
    boot_os:            'scibian8_ram'
    ipxebin:            'ipxe_noserial.bin'
----

The `cowsize` must be increased to 8GB from default 2GB on frontend and
graphical nodes because these nodes need much more packages to be installed at
boot time.

Then define the roles associated to the frontend and the compute nodes, for
example `front`, `cn` and `gn`. For these roles definitions, keep in mind the
following rules:

* The frontend role must include the `jobsched::client` while the compute nodes
  require the `jobsched::exec` profile instead.
* The `profiles::environment::userspace::packages` must include the
  `scibian-hpc-frontend` meta-package in the frontend nodes role,
  `scibian-hpc-compute` meta-package in the standard compute nodes and
  `scibian-hpc-graphical` meta-package on the graphical nodes.

The nodes must be added into the `master_network` hash in file
`$ADMIN/hpc-privatedata/hieradata/$CLUSTER/network.yaml` with all their network
interfaces and the MAC addresses of their network interface connected to the
_administration_ and their BMC.

Generate all the SSH host keys:

----
# puppet-hpc/scripts/sync-ssh-hostkeys.sh hpc-privatedata $CLUSTER
----

Push and apply the configuration to the admin and generic service nodes:

----
# hpc-config-push && clush -bg admin,service hpc-config-apply -v
----

Finally, boot all the nodes in PXE mode with Clara:

----
# clara ipmi pxe @front,@cn,@gn
# clara ipmi boot @front,@cn,@gn
----
